\section{Architecture}
\label{sec:architecture}
\begin{figure*}[!t]
  \centering
  \includegraphics[scale=0.5]{images/architecture_pipeline}
  \caption{Example of \SYS pipeline architecture.}
  \label{fig:architecture_pipeline}
\end{figure*}

% \begin{itemize}
%   \item Communication by Ã˜MQ (version 4.1.4)
%   \item Docker container for clustered deployment
%   \item Workers connected by routers: define worker's role and router's operating
%   \item Fire-and-forget messaging: a messsaging pattern in which we do not expect a direct response to the message, as opposed to request-response protocols
%   \item Based on Lua
% \end{itemize}

The architecture of \SYS{} comprises a combination two different types of components: \textsf{worker} and \textsf{router}.
A worker component continuously listens for incoming data by means of non-blocking I/O.
As soon as data flows in, some application-dependent business logic is applied.
A typical use-case is the deployment of a classic filter/map/reduce pattern from the functional programming paradigm~\cite{bird_introduction_1988}.
In that case, worker nodes execute only one function, namely \texttt{map}, \texttt{filter} or \texttt{reduce}.
A router acts as a message broker between workers in the pipeline and transfers data between workers according to some dispatching policy.
Figure~\ref{fig:architecture_pipeline} depicts a possible implementation of this dataflow pattern using the \SYS middleware.
%Datas in \textsc{SecureStreams} are streamed accross the process pipeline as shown in figure \ref{fig:architecture_pipeline}.

\SYS is designed to allow processing of sensible data inside SGX enclaves.
As explained in the previous section, the \emph{Enclave Page Cache} (EPC) is currently limited at 128\,MB.\footnote{Future releases of SGX might relax this limitation~\cite{mckeen2016intel}.}
To overcome these limitations, we settled on a lightweight yet efficient embeddable runtime, based on the Lua Virtual Machine~\cite{ierusalimschy_luaextensible_1996} and the corresponding multi-paradigm scripting language~\cite{lualang}.
The Lua runtime requires only few kilobytes of memory, and as such it represents an ideal candidate to execute in the limited space allowed by the EPC.
Moreover, the application-specific functions can be quickly prototyped in Lua, and even complex algorithms can be implemented with an almost 1:1 mapping from pseudo-code~\cite{leonini2009splay}.
We provide further implementation details of the embedding of the LuaVM inside an SGX enclave in Section~\ref{sec:implementation}.

%If a process exceeds the available memory, an encrypted pagination mechanism leads to performance leaks.
%Thus \textsc{SecureStreams} has been designed to use a Lua runtime.
%Lua is a lightweight multi-paradigm programming language designed primarily for embedded systems and clients\cite{ierusalimschy_luaextensible_1996}.
%Its runtime requires only few KB of memory, and thus fits easily in EPC.

Each component is wrapped inside a lightweight Linux container (in our case, the defacto industrial standard Docker~\cite{docker}).
Each container embeds all the required dependencies, while guaranteeing the correctness of their configuration, within an isolated and reproducible execution environment.
By doing so, a \SYS processing pipeline can be easily deployed without changing the source code on different public or private infrastructures, such as the Amazon EC2 Container Service~\cite{awsec2container}, either on a single machine or a cluster, using a Docker network and the Docker Swarm\cite{docker:swarm_2016} scheduler.

The communication between workers and routers leverages \zmq, a high-performance asynchronous messaging library~\cite{zero_mq}.
Each router component hosts inbound and outbound queues. %\vs{how much?}\ah{We don't know, so we should not talk about queue size. BTW, I don't understand your sentence. Do you missed a verb?}.
In particular, we use the \zmq's pipeline pattern with the \textsc{Push}-\textsc{Pull} protocol~\cite{zero_mq:pipeline}.
The inbound queue is a \textsc{Pull} socket.
The messages are streamed from a set of anonymous\footnote{\emph{Anonymous} is said about a peer without any identity: the server socket ignore which worker sent the message.} \textsc{Push} peers (\emph{e.g.}, the upstream workers in the pipeline).
The inbound queue uses a fair-queuing scheduling to deliver the message to the upper layer.
% dispatches the messages.\ah{that's not true, the fair-queuing algorithm operates at the level of the reception of the queue, and it does not dispatch anything, the message is passed to the outgoing socket/queue, that's it}
Conversely, the outbound queue is a \textsc{Push} socket, sending messages using a round-robin algorithm to a set of anonymous \textsc{Pull} peers, the downstream workers.
% \vs{if there is time, it could be useful to have a drawing that zooms into this aspect of the architecture, not the full pipeline}
This design allows to dynamically scale up and down each stage of the pipeline to adapt to the needs of the application or workload. %It is scalable in that nodes can join at any time.
Finally, \zmq guarantees that the messages are delivered across each stage via reliable TCP channels.
%The pattern is mostly reliable insofar as it will not discard messages unless a node disconnects unexpectedly.
%This fire-and-forget messaging is a messsaging pattern in which we do not expect a direct response to the message, as opposed to request-response protocols\cite{voelter_patterns_2003}.
% The absence of response to a message provides some relevant performances.

We define the processing pipeline components by means of the Docker Compose description language~\cite{docker:compose}.
Listing~\ref{pipeline-desc} shows a snippet of the description used to deploy the architecture in Figure~\ref{fig:architecture_pipeline}. 
Once the processing pipeline is defined, the containers must be deployed on the computing infrastructure.
We exploit the \texttt{constraint} mechanism to enforce the Docker Swarm's scheduler to deploy workers requiring SGX capabilities into appropriate hosts.

\begin{lstlisting}[language=YAML,caption={\SYS pipeline description. Few attributes (\texttt{volume}, \texttt{networks}, \texttt{env\_file}) omitted.},label=pipeline-desc][!t]
sgx_mapper:
  image: "${IMAGE_SGX}"
  entrypoint: ./start.sh sgx-mapper.lua
  environment:
    - TO=tcp://router_mapper_filter:5557
    - FROM=tcp://router_data_mapper:5556
    - "constraint:type==sgx"
  devices:
    - "/dev/isgx"

router_data_mapper:
  image: "${IMAGE}"
  hostname: router_data_mapper
  entrypoint: lua router.lua
  environment:
    - TO=tcp://*:5556
    - FROM=tcp://*:5555
    - "constraint:type==sgx"

data_stream:
  image: "${IMAGE}"
  entrypoint: lua data-stream.lua
  environment:
    - TO=tcp://routerdatamapper:5555
    - "constraint:type==sgx"
    - DATA_FILE=data/sample.csv
\end{lstlisting}


%\vs{Add some paragraphs to  detail how  the interaction with the SGX enclaves work in the context of \SYS}
%\vs{It should be useful to describe how the dataflow pipeline is mapped to the underlying cluster.}
