\section{Architecture}
\label{sec:architecture}
\begin{figure*}[!t]
  \centering
  \includegraphics[scale=0.5]{images/architecture_pipeline}
  \caption{Example of \SYS pipeline architecture.}
  \label{fig:architecture_pipeline}
\end{figure*}


The architecture of \SYS{} comprises a combination of two different types of components: \textsf{worker} and \textsf{router}.
A worker component continuously listens for incoming data by means of non-blocking I/O.
As soon as data flows in, an application-dependent business logic is applied.
A typical use-case is the deployment of a classic filter/map/reduce pattern from the functional programming paradigm~\cite{bird_introduction_1988}.
In such case, worker nodes execute only one function, namely \texttt{map}, \texttt{filter} or \texttt{reduce}.
A router acts as a message broker between workers in the pipeline and transfers data between them according to a given dispatching policy.
Figure~\ref{fig:architecture_pipeline} depicts a possible implementation of this dataflow pattern using the \SYS middleware.

\SYS is designed to allow processing of sensible data inside SGX enclaves.
As explained in the previous section, the \emph{Enclave Page Cache} (EPC) is currently limited at 128\,MB.\footnote{Future releases of SGX might relax this limitation~\cite{mckeen2016intel}.}
To overcome this limitation, we settled on a lightweight yet efficient embeddable runtime, based on the Lua Virtual Machine~\cite{ierusalimschy_luaextensible_1996} and the corresponding multi-paradigm scripting language~\cite{lualang}.
The Lua runtime requires only few kilobytes of memory, it is designed to be embeddable, and as such it represents an ideal candidate to execute in the limited space allowed by the EPC.
Moreover, the application-specific functions can be quickly prototyped in Lua, and even complex algorithms can be implemented with an almost 1:1 mapping from pseudo-code~\cite{leonini2009splay}.
We provide further implementation details of the embedding of the LuaVM inside an SGX enclave in Section~\ref{sec:implementation}.

%\rp{I would argue that the choice of Lua is not actually to overcome the memory limitation. I guess the majority of script interpreters would fit easily inside the 90MB. Besides, *ideal* is a quite strong claim. Of course we do need a script language since we cannot link code dinamically, but I would rather go with the programability arguments, the availability of RxLua, besides of course being easily embeddable and tiny.}

%If a process exceeds the available memory, an encrypted pagination mechanism leads to performance leaks.
%Thus \textsc{SecureStreams} has been designed to use a Lua runtime.
%Lua is a lightweight multi-paradigm programming language designed primarily for embedded systems and clients\cite{ierusalimschy_luaextensible_1996}.
%Its runtime requires only few KB of memory, and thus fits easily in EPC.

Each component is wrapped inside a lightweight Linux container (in our case, the defacto industrial standard Docker~\cite{docker}).
Each container embeds all the required dependencies, while guaranteeing the correctness of their configuration, within an isolated and reproducible execution environment.
By doing so, a \SYS processing pipeline can be easily deployed without changing the source code on different public or private infrastructures.
For instance, this will allow to deploy \SYS on Amazon EC2 Container Service~\cite{awsec2container}, where soon SkyLake-enabled instances will be made available~\cite{amazonskylake}, or similarly to Google Compute Engine~\cite{gceskylake}.
The deployment of the containers can be transparently executed on a single machine or a cluster, using a Docker network and the Docker Swarm\cite{docker:swarm_2016} scheduler.
%\rp{Does Amazon offer machines with Skylake processors with EPC enabled?}
%\ah{It's planned: https://aws.amazon.com/fr/about-aws/whats-new/2016/11/coming-soon-amazon-ec2-c5-instances-the-next-generation-of-compute-optimized-instances/ but we don't know if SGX will be enabled. Google intends also: http://fortune.com/2017/02/24/google-intel-cloud-chip/. Do we have to cite there references?}

The communication between workers and routers leverages \zmq, a high-performance asynchronous messaging library~\cite{zero_mq}.
Each router component hosts inbound and outbound queues.
In particular, the routers use the \zmq's Pipeline pattern~\cite{zero_mq:pipeline} with the \textsc{Push}-\textsc{Pull} socket types. 
%\rp{Is 'protocol' the best definition? I would rather call it a 'pattern'}\ah{It is, this is one of the different protocols of communication implemented in ZMQ, like explained in the target of the given pointer}\rp{The pointer does not mention protocol to refer to that. push/pull refers to the role of socket endpoints. It is not an agreement on format and content of exchanged messages, as a 'protocol' would be best understood by a common reader.}



The inbound queue is a \textsc{Pull} socket.
The messages are streamed from a set of anonymous\footnote{\emph{Anonymous} is said about a peer without any identity: the server socket ignore which worker sent the message.} \textsc{Push} peers (\emph{e.g.}, the upstream workers in the pipeline).
The inbound queue uses a fair-queuing scheduling to deliver the message to the upper layer.
Conversely, the outbound queue is a \textsc{Push} socket, sending messages using a round-robin algorithm to a set of anonymous \textsc{Pull} peers, \emph{e.g.} the downstream workers.
\begin{lstlisting}[language=YAML,caption={\SYS pipeline examples. Some attributes (\texttt{volume}, \texttt{networks}, \texttt{env\_file}) omitted.},label=pipeline-desc][!t]
sgx_mapper:
  image: "${IMAGE_SGX}"
  entrypoint: ./start.sh sgx-mapper.lua
  environment:
    - TO=tcp://router_mapper_filter:5557
    - FROM=tcp://router_data_mapper:5556
    - "constraint:type==sgx"
  devices:
    - "/dev/isgx"

router_data_mapper:
  image: "${IMAGE}"
  hostname: router_data_mapper
  entrypoint: lua router.lua
  environment:
    - TO=tcp://*:5556
    - FROM=tcp://*:5555
    - "constraint:type==sgx"

data_stream:
  image: "${IMAGE}"
  entrypoint: lua data-stream.lua
  environment:
    - TO=tcp://router_data_mapper:5555
    - "constraint:type==sgx"
    - DATA_FILE=the_stream.csv
\end{lstlisting}


% \vs{if there is time, it could be useful to have a drawing that zooms into this aspect of the architecture, not the full pipeline}
This design allows to dynamically scale up and down each stage of the pipeline in order to adapt it to application's needs or the workload.
Finally, \zmq guarantees that the messages are delivered across each stage via reliable TCP channels.
%The pattern is mostly reliable insofar as it will not discard messages unless a node disconnects unexpectedly.
%This fire-and-forget messaging is a messsaging pattern in which we do not expect a direct response to the message, as opposed to request-response protocols\cite{voelter_patterns_2003}.
% The absence of response to a message provides some relevant performances.


We define the processing pipeline components and their chaining by means of the Docker Compose's custom description language~\cite{docker:compose}.
Listing~\ref{pipeline-desc} shows a snippet of the description used to deploy the architecture in Figure~\ref{fig:architecture_pipeline}.
Once the processing pipeline is defined, the containers must be deployed on the computing infrastructure.
We exploit the \texttt{constraint} placement mechanism to enforce the Docker Swarm's scheduler to deploy workers requiring SGX capabilities into appropriate hosts.
In the example, an \texttt{sgx\_mapper} nodes is deployed on an SGX host by specyfing \texttt{"constraint:type==sgx"} in the Compose description.



%\vs{Add some paragraphs to  detail how  the interaction with the SGX enclaves work in the context of \SYS}
%\vs{It should be useful to describe how the dataflow pipeline is mapped to the underlying cluster.}
